{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa2ab8f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# This notebook demonstrates the AI pipeline for face personalization\n",
    "# We'll use a combination of face detection, style transfer, and template integration\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from facenet_pytorch import MTCNN\n",
    "import replicate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class FacePersonalizationPipeline:\n",
    "    def __init__(self):\n",
    "        # Initialize face detector\n",
    "        self.face_detector = MTCNN(keep_all=True)\n",
    "        \n",
    "        # Set up device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Replicate API token\n",
    "        self.replicate_token = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "    \n",
    "    def detect_and_extract_face(self, image_path):\n",
    "        \"\"\"Detect and extract face from image\"\"\"\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        boxes, probs = self.face_detector.detect(image_rgb)\n",
    "        \n",
    "        if boxes is None:\n",
    "            raise ValueError(\"No face detected in the image\")\n",
    "        \n",
    "        # Get the largest face\n",
    "        face_areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in boxes]\n",
    "        largest_idx = np.argmax(face_areas)\n",
    "        box = boxes[largest_idx]\n",
    "        \n",
    "        # Extract face with padding\n",
    "        padding = 50\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1 = max(0, int(x1) - padding)\n",
    "        y1 = max(0, int(y1) - padding)\n",
    "        x2 = min(image.shape[1], int(x2) + padding)\n",
    "        y2 = min(image.shape[0], int(y2) + padding)\n",
    "        \n",
    "        face_image = image[y1:y2, x1:x2]\n",
    "        \n",
    "        return face_image, (x1, y1, x2, y2)\n",
    "    \n",
    "    def apply_style_transfer(self, face_image, style=\"storybook\"):\n",
    "        \"\"\"Apply style transfer using Replicate API\"\"\"\n",
    "        # Save face image temporarily\n",
    "        temp_path = \"temp_face.png\"\n",
    "        cv2.imwrite(temp_path, face_image)\n",
    "        \n",
    "        # Prepare prompt based on style\n",
    "        style_prompts = {\n",
    "            \"storybook\": \"cartoon illustration of a child's face, storybook style, colorful, detailed, magical, fantasy\",\n",
    "            \"disney\": \"disney animation style, pixar character, 3D render, smooth lighting, cinematic\",\n",
    "            \"watercolor\": \"watercolor painting, soft edges, artistic, brush strokes, pastel colors\",\n",
    "            \"cartoon\": \"cartoon character, bold outlines, vibrant colors, comic book style\"\n",
    "        }\n",
    "        \n",
    "        prompt = style_prompts.get(style, style_prompts[\"storybook\"])\n",
    "        \n",
    "        # Use Replicate API\n",
    "        output = replicate.run(\n",
    "            \"stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b\",\n",
    "            input={\n",
    "                \"prompt\": prompt,\n",
    "                \"image\": open(temp_path, \"rb\"),\n",
    "                \"num_outputs\": 1,\n",
    "                \"guidance_scale\": 7.5,\n",
    "                \"num_inference_steps\": 30\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Clean up temp file\n",
    "        os.remove(temp_path)\n",
    "        \n",
    "        return output[0] if output else None\n",
    "    \n",
    "    def integrate_with_template(self, styled_face_url, template_path, face_position):\n",
    "        \"\"\"Integrate styled face into template\"\"\"\n",
    "        # Download styled face\n",
    "        import requests\n",
    "        from io import BytesIO\n",
    "        \n",
    "        response = requests.get(styled_face_url)\n",
    "        styled_face = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Load template\n",
    "        template = Image.open(template_path)\n",
    "        \n",
    "        # Resize face to fit template position\n",
    "        x1, y1, x2, y2 = face_position\n",
    "        face_width = x2 - x1\n",
    "        face_height = y2 - y1\n",
    "        \n",
    "        # Resize styled face to match original face dimensions\n",
    "        styled_face_resized = styled_face.resize((face_width, face_height))\n",
    "        \n",
    "        # Create result image\n",
    "        result = template.copy()\n",
    "        \n",
    "        # Paste styled face onto result\n",
    "        result.paste(styled_face_resized, (x1, y1))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_image(self, image_path, template_path, style=\"storybook\"):\n",
    "        \"\"\"Complete pipeline\"\"\"\n",
    "        # Step 1: Face detection and extraction\n",
    "        print(\"Step 1: Detecting face...\")\n",
    "        face_image, face_position = self.detect_and_extract_face(image_path)\n",
    "        \n",
    "        # Step 2: Style transfer\n",
    "        print(\"Step 2: Applying style transfer...\")\n",
    "        styled_face_url = self.apply_style_transfer(face_image, style)\n",
    "        \n",
    "        if not styled_face_url:\n",
    "            raise ValueError(\"Style transfer failed\")\n",
    "        \n",
    "        # Step 3: Template integration\n",
    "        print(\"Step 3: Integrating with template...\")\n",
    "        result = self.integrate_with_template(styled_face_url, template_path, face_position)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FacePersonalizationPipeline()\n",
    "    \n",
    "    # Process an image\n",
    "    result = pipeline.process_image(\n",
    "        image_path=\"child_photo.jpg\",\n",
    "        template_path=\"storybook_template.png\",\n",
    "        style=\"storybook\"\n",
    "    )\n",
    "    \n",
    "    # Save result\n",
    "    result.save(\"personalized_storybook.png\")\n",
    "    print(\"Personalized illustration saved!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
